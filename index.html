<!DOCTYPE html>
<html lang="en">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <title>Yuan Yao - School of Computing, National University of Singapore </title>
  <meta name="description"
    content="I am a Postdoc Research Fellow at the National University of Singapore, NExT++ Lab, working with Professor Chua Tat-Seng. Before that I recieved my Ph.D degree (advised by Professor Zhiyuan Liu at Tsinghua NLP Lab) and bachlor's degree from the Department of Computer Science and Technology of Tsinghua University. My research interests include multimodal large language models and natural language processing.">
  <meta name="keywords"
    content="Yuan Yao, NUS, National University of Singapore, THU, Tsinghua University, CST, Department of Computer Science and Technology, MLLMs, Multimodal Large Language Models, NLP, Natural Language Processing, Homepage">
  <meta name="author" content="Yuan Yao">

  <title>Resume - Start Bootstrap Theme</title>

  <!-- Bootstrap core CSS -->
  <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Custom fonts for this template -->
  <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet">
  <link href="vendor/fontawesome-free/css/all.min.css" rel="stylesheet">

  <!-- Custom styles for this template -->
  <link href="css/resume.css" rel="stylesheet">

</head>

<body id="page-top">

  <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
    <a class="navbar-brand js-scroll-trigger" href="#page-top">
      <span class="d-block d-lg-none">Yuan Yao</span>
      <span class="d-none d-lg-block">
        <img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="img/profile.jpg" alt="">
      </span>
    </a>

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav">
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#about">About Me</a>
        </li>

        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#publications">Publications</a>
        </li>
<!--        <li class="nav-item">-->
<!--          <a class="nav-link js-scroll-trigger" href="#projects">Projects</a>-->
<!--        </li>-->

        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#experience">Experience</a>
        </li>
<!--        <li class="nav-item">-->
<!--          <a class="nav-link js-scroll-trigger" href="#awards">Awards</a>-->
<!--        </li>-->
      </ul>
    </div>

    <div style="color: rgb(255,255,255);font-size: 10px;">© 2019 Yuan Yao 姚远. Powered by Startbootstrap-Agency.</div>
  </nav>

  <div class="container-fluid p-0">

    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="about">
      <div class="w-100">
        <h2 class="mb-0">Yuan
          <span class="text-primary">Yao</span>
        </h2>
        <br />

        <div class="mb-4">
          Postdoc Research Fellow<br />
          <b><a href="https://www.nextcenter.org">NExT++ Lab,</a></b><br />
          <b><a href="https://www.comp.nus.edu.sg">School of Computing,</a></b><br />
          <b><a href="https://www.nus.edu.sg">National University of Singapore.</a></b>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-4">
          <div class="resume-content">
            <h3 class="mb-0"> Contact</h3>
            <table>
              <tr>
                <td><i class="far fa-envelope"></i>&nbsp;</td>
                <td>yaoyuanthu [at]&nbsp;163&nbsp;[dot]&nbsp;com</td>
              </tr>
              <tr>
                <td><i class="fas fa-map-marker-alt"></i>&nbsp;</td>
                <td>National University of Singapore</td>
              </tr>
              <tr>
                <td><i class="fas fa-graduation-cap"></i>&nbsp;</td>
                <td><a href="https://scholar.google.com/citations?user=3NWfi3YAAAAJ"><b>Google Scholar</b></a></td>
              </tr>
            </table>

          </div>
        </div>


        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-4">
          <div class="resume-content">
            <h3 class="mb-0"> About me </h3>
            <div class="mb-0">
              Hi! I am a postdoc research fellow at the
              <a href="https://www.nus.edu.sg" target="_blank"><b>National University of Singapore</b></a>, where I am a member of the
              <a href="https://www.nextcenter.org" target="_blank"><b>NExT++ Lab</b></a>, working with <a href="https://www.comp.nus.edu.sg/cs/people/chuats/" target="_blank"><b>Professor Chua Tat-Seng</b></a>.
              I received my Ph.D. degree from the Department of Computer Science and Technology of <a href="https://www.tsinghua.edu.cn/en/" target="_blank"><b>Tsinghua University</b></a>, advised by <a href="http://nlp.csai.tsinghua.edu.cn/~lzy/" target="_blank"><b>Professor Zhiyuan Liu</b></a> at the <a href="http://thunlp.org/site2/" target="_blank"><b>Tsinghua Natural Language Processing Lab</b></a>. Before I became a Ph.D. student, I also received my
              bachelor's degree from Tsinghua University</a>. My research interests include multimodal large language models and natural language processing. I lead the <a href="https://github.com/OpenBMB/MiniCPM-o" target="_blank"><b>MiniCPM-V and MiniCPM-o</b></a> series of efficient multimodal large language models.
            </div>
            <br> 
            <div class="mb-0">
              <a href="https://collegeai.tsinghua.edu.cn/" target="_blank"><b>I will join College of AI, Tsinghua University as a Tenure-track Assistant Professor in October, 2025. I'm looking for highly motivated PhD students and research interns interested in multimodal large language models.</b></a> 
            </div>
          </div>
        </div>
      </div>
    </section>


    <hr class="m-0">

    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="publications">
      <div class="w-100">
        <h2 class="mb-5">PUBLICATIONS</h2>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-2">
          <div class="resume-content">

            <h3 class="mb-0">2025</h3>
            <div>
              1. <b>Yuan Yao</b>, Tianyu Yu, Ao Zhang, Chongyi Wang,Junbo Cui, Hongji Zhu, Tianchi Cai, Haoyu Li, Weilin Zhao, Huarong Zhou, Zhihui He, Zhensheng Zou, Haoye Zhang, Shengding Hu, Zhi Zheng, Jie Zhou, Jie Cai, Jie Zhou, Xu Han, Guoyang Zeng, Dahai Li, Zhiyuan Liu, Maosong Sun. MiniCPM-V: A GPT-4V Level Multimodal LLM on Your Phone. <b>Nature Communications.</b> <a href="https://github.com/OpenBMB/MiniCPM-V">[Project: MiniCPM-V]</a>
            </div>

            <div>
              2. Tianyu Yu, Bo Ji, Shouli Wang, Shu Yao, Zefan Wang, Ganqu Cui, Lifan Yuan, Ning Ding, <b>Yuan Yao†</b>, Zhiyuan Liu, Maosong Sun, Tat-Seng Chua. († indicates corresponding author) RLPR: Scaling RLVR to General Domain without Verifiers. Preprint.</b> </a>
            </div>
               
            <div>
              3. Ji Qi, <b>Yuan Yao†</b>, Yushi Bai, Bin Xu, Juanzi Li, Zhiyuan Liu, Tat-Seng Chua. († indicates corresponding author) Quicksviewer: An LMM for Efficient Video Understanding via Reinforced Compression of Video Cubes. Preprint </a>
            </div>

            <div>
              4. Wentong Chen, Junbo Cui, Jinyi Hu, Yujia Qin, Junjie Fang, Yue Zhao, Chongyi Wang, Jun Liu, Guirong Chen, Yupeng Huo, <b>Yuan Yao†</b>, Yankai Lin, Zhiyuan Liu, Maosong Sun. († indicates corresponding author) GUICourse: From General Vision Language Models to Versatile GUI Agents. ACL 2025. </a>
            </div>

            <div>
              5. Ganqu Cui, Lifan Yuan, Zefan Wang, Hanbin Wang, Wendi Li, Bingxiang He, Yuchen Fan, Tianyu Yu, Qixin Xu, Weize Chen, Jiarui Yuan, Huayu Chen, Kaiyan Zhang, Xingtai Lv, Shuo Wang, <b>Yuan Yao</b>, Xu Han, Hao Peng, Yu Cheng, Zhiyuan Liu, Maosong Sun, Bowen Zhou, Ning Ding. Process Reinforcement through Implicit Rewards. Preprint. </a>
            </div>

            <div>
              6. Tianyu Yu, Haoye Zhang, Qiming Li, Qixin Xu, <b>Yuan Yao†</b>, Da Chen, Xiaoman Lu, Ganqu Cui, Yunkai Dang, Taiwen He, Xiaocheng Feng, Jun Song, Bo Zheng, Zhiyuan Liu, Tat-Seng Chua, Maosong Sun. († indicates corresponding author) RLAIF-V: Open-Source AI Feedback Leads to Super GPT-4V Trustworthiness. CVPR 2025. <b>Highlights.</b> </a>
            </div>
            
            <div>
              7. <b>Yuan Yao</b>, Tianyu Yu, Chongyi Wang, Junbo Cui, Bokai Xu, Hongji Zhu, Tianchi Cai, Fuwei Huang, Tianran Wang, Wenshuo Ma, etc. MiniCPM-o: A GPT-4o Level MLLM for Vision, Speech, and Multimodal Live Streaming on Your Phone. <a href="https://github.com/OpenBMB/MiniCPM-V">[Project: MiniCPM-o]</a>
            </div>
            
          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-2">
          <div class="resume-content">

            
            

            <h3 class="mb-0">2024</h3>

            <div>
              1. Shengding Hu, Yuge Tu, Xu Han, Chaoqun He, Ganqu Cui, Xiang Long, Zhi Zheng, Yewei Fang, Yuxiang Huang, Weilin Zhao, Xinrong Zhang, Zheng Leng Thai, Kaihuo Zhang, Chongyi Wang, <b>Yuan Yao</b>, Chenyang Zhao, Jie Zhou, Jie Cai, Zhongwu Zhai, Ning Ding, Chao Jia, Guoyang Zeng, Dahai Li, Zhiyuan Liu, Maosong Sun. MiniCPM: Unveiling the Potential of End-side Large Language Models. COLM 2024<a href="https://github.com/OpenBMB/MiniCPM">. [Project: MiniCPM]</a>
            </div>

            <div>2. Zanlin Ni, Yulin Wang, Renping Zhou, Rui Lu, Jinyi Hu, Zhiyuan Liu, <b>Yuan Yao†</b>, Gao Huang. († indicates corresponding author) AdaNAT: Exploring Adaptive Policy for Token-Based Image Generation. ECCV 2024.</div>

            <div>3. Ao Zhang, <b>Yuan Yao†</b>, Wei Ji, Zhiyuan Liu, Tat-Seng Chua. († indicates corresponding author) NExT-Chat: An LMM for Chat, Detection and Segmentation. ICML 2024. </div>

            <div>
              4. Tianyu Yu, <b>Yuan Yao†</b>, Haoye Zhang, Taiwen He, Yifeng Han, Ganqu Cui, Jinyi Hu, Zhiyuan Liu, Hai-Tao Zheng, Maosong Sun, Tat-Seng Chua. († indicates corresponding author) RLHF-V: Towards Trustworthy MLLMs via Behavior Alignment from Fine-grained Correctional Human Feedback. CVPR 2024. <a href="https://rlhf-v.github.io/">[Project: RLHF-V]</a>
            </div>

            <div>
              5. Zanlin Ni, Yulin Wang, Renping Zhou, Jiayi Guo, Jinyi Hu, Zhiyuan Liu, Shiji Song, <b>Yuan Yao†</b>, Gao Huang. († indicates corresponding author) Revisiting Non-Autoregressive Transformers for Efficient Image Synthesis. CVPR 2024.
            </div>

            <div>
              6. Jinyi Hu, <b>Yuan Yao†</b>, Chongyi Wang, Yinxu Pan, Shan Wang, Qianyu Chen, Tianyu Yu, Yue Zhao, Xu Han, Jiao Xue, Dahai Li, Zhiyuan Liu†, Maosong Sun†. († indicates corresponding author) Large Multilingual Models Pivot Zero-shot Multimodal Learning across Languages. ICLR 2024. <b>Spotlight.</b> <a href="https://github.com/OpenBMB/VisCPM">[Project: VisCPM]</a>
            </div>

            <div>
              7. Jifan Yu, Xiaozhi Wang, Shangqing Tu, Shulin Cao, Daniel Zhang-Li, Xin Lv, Hao Peng, Zijun Yao, Xiaohan Zhang, Hanming Li, Chunyang Li, Zheyuan Zhang, Yushi Bai, Yantao Liu, Amy Xin, Kaifeng Yun, Linlu GONG, Nianyi Lin, Jianhui Chen, Zhili Wu, Yunjia Qi, Weikai Li, Yong Guan, Kaisheng Zeng, Ji Qi, Hailong Jin, Jinxin Liu, Yu Gu, <b>Yuan Yao</b>, Ning Ding, Lei Hou, Zhiyuan Liu, Xu Bin, Jie Tang, Juanzi Li. KoLA: Carefully Benchmarking World Knowledge of Large Language Models. ICLR 2024. <a href="https://kola.xlore.cn">[Project: KoLA]</a> 
            </div>

            <div>
              8. <b>Yuan Yao</b>, Ao Zhang, Zhengyan Zhang, Zhiyuan Liu, Tat-Seng Chua, Maosong Sun. CPT: Colorful Prompt Tuning for Pre-trained Vision-Language Models. AI Open. 2024.
            </div>    
            
          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-2">
          <div class="resume-content">
            <h3 class="mb-0">2023</h3>

            <div>
              1. Ao Zhang, <b>Yuan Yao†</b>, Wei Ji, Zhiyuan Liu, Tat-Seng Chua. († indicates corresponding author) NExT-Chat: An LMM for Chat, Detection and Segmentation. Preprint.
            </div>

            <div>
              2. Tianyu Yu, Jinyi Hu, <b>Yuan Yao†</b>, Haoye Zhang, Yue Zhao, Chongyi Wang, Shan Wang, Yinxu Pan, Jiao Xue, Dahai Li, Zhiyuan Liu†, Hai-Tao Zheng, Maosong Sun†. († indicates corresponding author) Reformulating Vision-Language Foundation Models and Datasets Towards Universal Multimodal Assistants. Preprint.
            </div>

            <div>
              3. Ao Zhang, Hao Fei†, <b>Yuan Yao†</b>, Wei Ji, Li Li, Zhiyuan Liu, Tat-Seng Chua. († indicates corresponding author) Transfer Visual Prompt Generator across LLMs. NeurIPS 2023.
            </div>

            <div>
              4. <b>Yuan Yao</b>, Tianyu Yu, Ao Zhang, Mengdi Li, Ruobing Xie, Cornelius Weber, Zhiyuan Liu, Haitao Zheng, Stefan Wermter, Tat-Seng Chua, Maosong Sun. Visually Grounded Commonsense Knowledge Acquisition. AAAI 2023. <b>Oral presentation</b>.
            </div>
            
          </div>
        </div>


        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-2">
          <div class="resume-content">
            <h3 class="mb-0">2022</h3>

            <div>
              1. <b>Yuan Yao</b>, Qianyu Chen, Ao Zhang, Wei Ji, Zhiyuan Liu, Tat-Seng Chua, Maosong Sun. (* indicates equal contribution) PEVL: Position-enhanced Pre-training and Prompt Tuning for Vision-language Models. EMNLP 2022. 
            </div>

            <div>
              2. Ao Zhang*, <b>Yuan Yao</b>*, Qianyu Chen, Wei Ji, Zhiyuan Liu, Maosong Sun, Tat-Seng Chua. (* indicates equal contribution) Fine-Grained Scene Graph Generation with Data Transfer. ECCV 2022. <b>Oral presentation</b>.
            </div>
            
            <div>
              3. <b>Yuan Yao</b>, Bowen Dong, Ao Zhang, Zhengyan Zhang, Ruobing Xie, Zhiyuan Liu, Leyu Lin, Maosong Sun, Jianyong Wang. Prompt Tuning for Discriminative Pre-trained Language Models. Findings of ACL 2022. 
            </div>

            <div> 
              4. Zheni Zeng*, <b>Yuan Yao</b>*, Zhiyuan Liu and Maosong Sun. (* indicates equal contribution) A Deep-learning System Bridging Molecule Structure and Biomedical Text with Comprehension Comparable to Human Professionals. Nature Communications, 2022. <b>Editors' Highlights</b>.
            </div>
            
          </div>
        </div>


         <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-2">
          <div class="resume-content">
            <h3 class="mb-0">2021</h3>        
            
            <div>
              1. <b>Yuan Yao</b>, Jiaju Du, Yankai Lin , Peng Li, Zhiyuan Liu, Jie Zhou and Maosong Sun. (* indicates equal contribution) CodRED: A Cross-Document Relation Extraction Dataset for Acquiring Knowledge in the Wild. EMNLP 2021. 
            </div>
            
           <div>
              2. <b>Yuan Yao</b>, Ao Zhang, Xu Han, Mengdi Li, Cornelius Weber, Zhiyuan Liu, Stefan Wermter and Maosong Sun. (* indicates equal contribution) Visual Distant Supervision for Scene Graph Generation. ICCV 2021. 
            </div>

            <div>
              3. Fanchao Qi*, <b>Yuan Yao</b>*, Sophia Xu*, Zhiyuan Liu and Maosong Sun. (* indicates equal contribution) Turn the Combination Lock: Learnable Textual Backdoor Attacks via Word Substitution. ACL 2021. 
            </div>

            <div>
              4. Kai Zhang*, <b>Yuan Yao</b>*, Ruobing Xie, Xu Han, Zhiyuan Liu, Fen Lin, Leyu Lin and Maosong Sun. (* indicates equal contribution) Open Hierarchical Relation Extraction. NAACL-HLT 2021. 
            </div>

            <div>
              5. <b>Yuan Yao</b>, Haoxi Zhong, Zhengyan Zhang, Xu Han, Xiaozhi Wang, Kai Zhang, Chaojun Xiao, Guoyang Zeng, Zhiyuan Liu and Maosong Sun. (* indicates equal contribution) Adversarial Language Games for Advanced Natural Language Intelligence. AAAI 2021. 
            </div>

            <div>
              6. Zheni Zeng, Chaojun Xiao, <b>Yuan Yao</b>, Ruobing Xie, Zhiyuan Liu, Fen Lin, Leyu Lin and Maosong Sun. Knowledge Transfer via Pre-training for Recommendation: A Review and Prospect. Frontiers in Big Data, 2021.
            </div>
          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-2">
          <div class="resume-content">
            <h3 class="mb-0">2020</h3>
            <div>
              1. Bowen Dong*, <b>Yuan Yao</b>*, Ruobing Xie, Tianyu Gao, Xu Han, Zhiyuan Liu, Fen Lin, Leyu Lin and Maosong Sun. (* indicates equal contribution) Meta-Information Guided Meta-Learning for Few-Shot Relation Classification. COLING 2020. 
            </div>

            <div>
              2. Chaojun Xiao, <b>Yuan Yao</b>, Ruobing Xie, Xu Han, Zhiyuan Liu, Maosong Sun, Fen Lin and Leyu Lin. Denoising Relation Extraction from Document-level Distant Supervision. EMNLP 2020. 
            </div>

            <div>
              3. Stefan Heinrich, <b>Yuan Yao</b>, Tobias Hinz, Zhiyuan Liu, Thomas Hummel, Matthias Kerzel, Cornelius Weber and Stefan Wermter. Crossmodal Language Grounding in an Embodied Neurocognitive Model. Frontiers in Neurorobitics, 2020.
            </div>

          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-2">
          <div class="resume-content">
            <h3 class="mb-0">2019</h3>

            <div>
              1. Xu Han, Tianyu Gao, <b>Yuan Yao</b>, Demin Ye, Zhiyuan Liu, Maosong Sun.
              OpenNRE: An Open and Extensible Toolkit for Neural Relation Extraction. EMNLP 2019. Demo paper.
            </div>

            <div>
              2. Ruidong Wu*, <b>Yuan Yao</b>*, Xu Han, Ruobing Xie, Zhiyuan Liu, Fen Lin, Leyu Lin, Maosong Sun. (* indicates equal contribution) Open Relation Extraction: Relational Knowledge Transfer from Supervised Data to Unsupervised Data. EMNLP 2019. 
            </div>

            <div>
              3. <b>Yuan Yao</b>, Deming Ye, Peng Li, Xu Han, Yankai Lin, Zhenghao Liu, Zhiyuan Liu, Lixin Huang, Jie Zhou, Maosong Sun. (* indicates equal contribution) DocRED: A Large-Scale Document-Level Relation Extraction Dataset. ACL 2019. 
            </div>

            <div>
              4. Jiayuan Mao*, <b>Yuan Yao</b>*, Stefan Heinrich, Tobias Hinz, Cornelius Weber, Stefan Wermter, Zhiyuan Liu, Maosong Sun. (* indicates equal contribution) Bootstrapping Knowledge Graphs From Images and Text. Frontiers in Neurorobitics, 2019.
            </div>

            <div>
              5. Ruobing Xie, Stefan Heinrich, Zhiyuan Liu, Cornelius Weber, <b>Yuan Yao</b>, Stefan Wermter, Maosong Sun. Integrating Image-based and Knowledge-based Representation Learning. IEEE Transactions on Cognitive and Developmental Systems, 2019.
            </div>

          </div>
        </div>



        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-2">
          <div class="resume-content">
            <h3 class="mb-0">2018</h3>

            <div>
              1. Xu Han, Hao Zhu, Pengfei Yu, Ziyun Wang, <b>Yuan Yao</b>, Zhiyuan Liu, Maosong Sun. FewRel: A Large-Scale Supervised Few-shot Relation Classification Dataset with State-of-the-Art Evaluation. EMNLP 2018. 
            </div>


          </div>
        </div>

      </div>
    </section>



    <hr class="m-0">

    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="experience">
      <div class="w-100">
        <h2 class="mb-5">EXPERIENCE</h2>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-2">
          <div class="resume-content">
            <h3 class="mb-0">Postdoc Researcher</h3>
            <div>School of Computing,</div>
            <div class="mb-0">National University of Singapore.</div>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">September 2023 - Present</span>
          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-2">
          <div class="resume-content">
            <h3 class="mb-0">Ph.D. in Computer Science
            </h3>
            <div>Department of Computer Science and Technology,</div>
            <div class="mb-0">Tsinghua University, Beijing, China.</div>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">August 2018 - July 2023</span>
          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-2">
          <div class="resume-content">
            <h3 class="mb-0">Bachelor of Engineering</h3>
            <div>Department of Computer Science and Technology,</div>
            <div class="mb-0">Tsinghua University, Beijing, China.</div>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">August 2014 - July 2018</span>
          </div>
        </div>

<!--        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-2">-->
<!--          <div class="resume-content">-->
<!--            <h3 class="mb-0"> Reviewer </h3>-->
<!--            <div class=" mb-0">SIGIR 2018, IJCAI 2018, AAAI 2019, NAACL-HLT 2019, EMNLP-IJCNLP 2019, <br /> ACL 2020,-->
<!--              WWW 2020, CIKM 2020, EMNLP 2020, COLING 2020, NLPCC 2020, AACL 2020, <br /> NAACL 2021.-->
<!--            </div>-->
<!--          </div>-->
<!--          &lt;!&ndash; <div class="resume-date text-md-right">-->
<!--            <span class="text-primary">2018 - Present</span>-->
<!--          </div> &ndash;&gt;-->
<!--        </div>-->


        <!-- <h3 class="mb-0">TA</h3>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-0">
          <div class="resume-content">
            <div>
              Natural Language Processing, Tsinghua University.<br />
            </div>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">2019 - 2023</span>
          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-0">
          <div class="resume-content">
            <div>
              Social Computing, Tsinghua University.
            </div>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">2020</span>
          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-2">
          <div class="resume-content">
            <div>
              Media Programming, Tsinghua University.
            </div>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">2017 - 2019</span>
          </div>
        </div>   -->

        <br>
        <hr class="m-0">
        <br>
        
        <h2 class="mb-5">AWARDS</h2>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-2">
        <div class="resume-content">
            <div class="mb-0">Outstanding Doctoral Dissertation Award of Wu Wenjun AI Science and Technology Award, Chinese Association for Artificial Intelligence.</div>
          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-2">
        <div class="resume-content">
            <div class="mb-0">10 Major Sci-Tech Achievements, Zhongguancun Forum Annual Conference.</div>
          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-2">
        <div class="resume-content">
            <div class="mb-0">Spotlight Recipient of the WAIC Yunfan Award, World Artificial Intelligence Conference.</div>
          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-2">
          <div class="resume-content">
            <div class="mb-0">Intel China Academic Achievement Award, Intel.</div>
          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-2">
          <div class="resume-content">
            <div class="mb-0">HuggingFace Most Liked and Most Downloaded Open-Source AI Models, HuggingFace.</div>
          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-2">
        <div class="resume-content">
            <div class="mb-0">Outstanding Cases of Jointly Building a Community with a Shared Future in Cyberspace, World Internet Conference.</div>
          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-2">
        <div class="resume-content">
            <div class="mb-0">Tsinghua Shuimu Scholar, Tsinghua University.</div>
          </div>
        </div>



    </section>

    

        





<!-- <hr class="m-0">-->

<!--    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="awards">-->
<!--      <div class="w-100">-->
<!--        <h2 class="mb-5">Awards</h2>-->
<!--        <h3 class="mb-0">Ph.D. student</h3>-->

<!--        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-0">-->
<!--          <div class="resume-content">-->
<!--            <div>-->
<!--              Microsoft Research Asia (MSRA) Fellowship.  <br />-->
<!--              Tsinghua-Sohu Scholarship, Tsinghua University.-->
<!--            </div>-->
<!--          </div>-->
<!--          <div class="resume-date text-md-right">-->
<!--            <span class="text-primary">2020</span>-->
<!--          </div>-->
<!--        </div> -->
<!--        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-0">-->
<!--          <div class="resume-content">-->
<!--            <div>-->
<!--              Zhongshimo Scholarship, Tsinghua University. <br />-->
<!--              Jiang Nanxiang Scholarship, Tsinghua University.<br />-->
<!--              National Scholarship for Ph.D Student, Tsinghua University.<br />-->
<!--              Tencent Rhino-Bird Elite Training Program Excellent Graduate.-->
<!--            </div>-->
<!--          </div>-->
<!--          <div class="resume-date text-md-right">-->
<!--            <span class="text-primary">2019</span>-->
<!--          </div>-->
<!--        </div>-->

<!--        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-2">-->
<!--          <div class="resume-content">-->
<!--            <div>-->
<!--              National Scholarship for Ph.D Student, Tsinghua University.-->
<!--            </div>-->
<!--          </div>-->
<!--          <div class="resume-date text-md-right">-->
<!--            <span class="text-primary">2018</span>-->
<!--          </div>-->
<!--        </div>-->

<!--        <h3 class="mb-0">Bachelor</h3>-->
<!--        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-0">-->
<!--          <div class="resume-content">-->
<!--            <div>-->
<!--              Excellent Graduate, Tsinghua University.<br />-->
<!--              Excellent Bachelor Thesis, Tsinghua University.<br />-->
<!--              Excellent Graduate, Dept. of CS&T, Tsinghua University.<br />-->
<!--            </div>-->
<!--          </div>-->
<!--          <div class="resume-date text-md-right">-->
<!--            <span class="text-primary">2017</span>-->
<!--          </div>-->
<!--        </div>-->

<!--        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-0">-->
<!--          <div class="resume-content">-->
<!--            <div>-->
<!--              First-class Overall Excellence Scholarship, Tsinghua University.<br />-->
<!--            </div>-->
<!--          </div>-->
<!--          <div class="resume-date text-md-right">-->
<!--            <span class="text-primary">2016</span>-->
<!--          </div>-->
<!--        </div>-->

<!--        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-0">-->
<!--          <div class="resume-content">-->
<!--            <div>-->
<!--              First-class Science and Technology Innovation Excellence Scholarship, Tsinghua University.<br />-->
<!--            </div>-->
<!--          </div>-->
<!--          <div class="resume-date text-md-right">-->
<!--            <span class="text-primary">2015</span>-->
<!--          </div>-->
<!--        </div>-->

<!--        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-2">-->
<!--          <div class="resume-content">-->
<!--            <div>-->
<!--              First-class Academic Excellence Scholarship, Tsinghua University.<br />-->
<!--            </div>-->
<!--          </div>-->
<!--          <div class="resume-date text-md-right">-->
<!--            <span class="text-primary">2014</span>-->
<!--          </div>-->
<!--        </div>-->

<!--        <h3 class="mb-0">high school</h3>-->
<!--        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-0">-->
<!--          <div class="resume-content">-->
<!--            <div>-->
<!--              Silver medal in National Olympiad in Information, China.<br />-->
<!--            </div>-->
<!--          </div>-->
<!--          <div class="resume-date text-md-right">-->
<!--            <span class="text-primary">2012</span>-->
<!--          </div>-->
<!--        </div>-->

<!--        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-2">-->
<!--          <div class="resume-content">-->
<!--            <div>-->
<!--              Golden medal in National Olympiad in Information, China.<br />-->
<!--            </div>-->
<!--          </div>-->
<!--          <div class="resume-date text-md-right">-->
<!--            <span class="text-primary">2011</span>-->
<!--          </div>-->
<!--        </div>-->

<!--      </div>-->
<!--    </section> -->

  </div>

  <script src="vendor/jquery/jquery.min.js"></script>
  <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="vendor/jquery-easing/jquery.easing.min.js"></script>
  <script src="js/resume.min.js"></script>

</body>

</html>
